{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d0c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=G7FIQ9fXl6U&list=PLM8wYQRetTxBkdvBtz-gw8b9lcVkdXQKV&index=8\n",
    "# Also, see lec 2 in word document on markov process in Wk 3 of Adv. Pred.Ana. in UEL folder \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 3 states, burger (0), pizza (1), hotdog (2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86bbd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Burger', 1: 'Pizza', 2: 'Hotdog'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dictionary to Assign states \n",
    "\n",
    "state = {\n",
    "    0 : \"Burger\",\n",
    "    1 : \"Pizza\",\n",
    "    2 : \"Hotdog\"\n",
    "}\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a729ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.6, 0.2],\n",
       "       [0.3, 0. , 0.7],\n",
       "       [0.5, 0. , 0.5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create transition prob. matrix (tpm)\n",
    "\n",
    "mat_A = np.array([[0.2, 0.6, 0.2],\n",
    "             [0.3, 0.0, 0.7], \n",
    "             [0.5, 0.0, 0.5]])                        # we use the np.array func, and enter arguments by row\n",
    "\n",
    "mat_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a897392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burger ---> Hotdog ---> Hotdog ---> Hotdog ---> Hotdog ---> Burger ---> Burger ---> Pizza ---> Hotdog ---> Hotdog ---> Hotdog ---> Burger ---> Burger ---> Pizza ---> Hotdog ---> stop\n"
     ]
    }
   ],
   "source": [
    "#Simulating a random walk on the markov chain\n",
    "\n",
    "n=15 #in the R practice this might have been n_t (from markov cohort 2_2)\n",
    "start_state = 0\n",
    "print(state[start_state], \"--->\", end = \" \")       # prints the name of the starting state. so for e.g in dictionary above: state[0] corresponds to \"Burger\"\n",
    "prev_state = start_state                          # The end=\" \": prevents a newline character from being printed, allowing subsequent states to be printed on the same line.\n",
    "\n",
    "while n-1:\n",
    "    curr_state = np.random.choice([0, 1, 2], p = mat_A[prev_state])       # from np manual (https://numpy.org/doc/2.1/reference/random/generated/numpy.random.choice.html) -> random.choice(a, size=None, replace=True, p=None); here p = mat_A....\n",
    "                                                                          #so basically, the func randomly choses from the 1D array of states, based on the tpm associated with the elements in the 1D array ([0,1,2])\n",
    "                                                                          # prv_state is in the while loop as equal to the curr_state. However, as at n-1 =14, the prv_state = start_state (@ n=15) = 0\n",
    "                                                                          # therefore, at this point in the code, we are essentially saying mat_A[0] = [0.2, 0.6, 0.2]. so make a random choice from 1D array of states based on a previous state being burger as written at the start (before the while loop)\n",
    "    \n",
    "    print(state[curr_state], \"--->\", end = \" \")                           # Then pass the new \"curr_state\" to the dictionarry (in the 2nd cell above), print out result.\n",
    "    prev_state = curr_state                                               # By the time the system reads the end of the while loop, prev_state will be equal to curr_state, and then the next step starts (n=13); this iterates WHILE \"n-1\" (Basically n-1 in the while loop means that we should continue till n<1)\n",
    "    n-=1\n",
    "print(\"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1538284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotdog ---> Hotdog ---> Burger ---> Pizza ---> Hotdog ---> Burger ---> Pizza ---> Hotdog ---> Burger ---> Pizza ---> Hotdog ---> Hotdog ---> Burger ---> Pizza ---> Hotdog ---> stop\n"
     ]
    }
   ],
   "source": [
    "#let's simulate again but try using a differnt starting state (e.g. hotdog)\n",
    "\n",
    "n=15 \n",
    "start_state = 2\n",
    "print(state[start_state], \"--->\", end = \" \")       # prints the name of the starting state. so for e.g in dictionary above: state[0] corresponds to \"Burger\"\n",
    "prev_state = start_state                          # The end=\" \": prevents a newline character from being printed, allowing subsequent states to be printed on the same line.\n",
    "\n",
    "while n-1:\n",
    "    curr_state = np.random.choice([0, 1, 2], p = mat_A[prev_state])       \n",
    "    print(state[curr_state], \"--->\", end = \" \")                           \n",
    "    prev_state = curr_state                                              \n",
    "    n-=1\n",
    "print(\"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "276a2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "π =  [0.351584 0.210855 0.437562]\n"
     ]
    }
   ],
   "source": [
    "#finding the stationary Prb distribution of the markov chain (Approach 1: Monte Carlo Simulation)\n",
    "\n",
    "steps = 10**6\n",
    "start_state = 0\n",
    "pi = np.array([0, 0, 0])          #at this point we set up for a count of total number of occurence of each state on the state space\n",
    "pi[start_state] = 1        #basically the staring state pi[0] = certainly burger = 100%\n",
    "prev_state = start_state\n",
    "\n",
    "i = 0\n",
    "while i<steps:\n",
    "    curr_state = np.random.choice([0, 1, 2], p = mat_A[prev_state])\n",
    "    pi[curr_state] +=1    #counts freq of current state + 1\n",
    "    prev_state = curr_state\n",
    "    i +=1\n",
    "    \n",
    "print(\"π = \", pi/steps)\n",
    "\n",
    "# accuracy of the final answer increases asso. of steps increases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c31c03cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat_A^n = \n",
      " [[0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]] \n",
      "\n",
      "π =  [0.35211268 0.21126761 0.43661972]\n"
     ]
    }
   ],
   "source": [
    "#finding the stationary Prb distribution of the markov chain (Approach 2: Repeated Matrix Multiplication)\n",
    "#Basically finding the stationary tpm by multilplyin the initial matrix by itself until no change (see word doc on markov process wk3, UEL)\n",
    "\n",
    "steps = 10**3\n",
    "mat_A_n = mat_A\n",
    "\n",
    "i=0\n",
    "while i<steps:\n",
    "    mat_A_n = np.matmul(mat_A_n, mat_A)  #Matrix product of two arrays.\n",
    "    i+=1\n",
    "\n",
    "print(\"mat_A^n = \\n\", mat_A_n, \"\\n\")\n",
    "print(\"π = \", mat_A_n[0])\n",
    "\n",
    "#This approach is much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c8432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left eigen vectors = \n",
      " [[-0.58746336+0.j         -0.16984156-0.35355339j -0.16984156+0.35355339j]\n",
      " [-0.35247801+0.j          0.67936622+0.j          0.67936622-0.j        ]\n",
      " [-0.72845456+0.j         -0.50952467+0.35355339j -0.50952467-0.35355339j]] \n",
      "\n",
      "eigen values = \n",
      " [ 1.  +0.j        -0.15+0.3122499j -0.15-0.3122499j]\n"
     ]
    }
   ],
   "source": [
    "#finding the stationary Prb distribution of the markov chain (Approach 3: finding the left eigenvector)\n",
    "\n",
    "import scipy.linalg     # This line imports the linalg module from the scipy (Scientific Python) library.  scipy provides many useful functions for scientific computing, including linear algebra.\n",
    "values, left = scipy.linalg.eig(mat_A, right = False, left = True)  # This is the core of the code.  It calls the scipy.linalg.eig function with the ff arguments:\n",
    "                                                                    # we know mat_A is the input tpm. \"right=False\": This argument tells the function not to calculate the right eigenvectors. Right eigenvectors are often calculated, but in this case, the code explicitly sets right=False because it only needs the left eigenvectors.\n",
    "                                                                    # left=True: This argument tells the function to calculate the left eigenvectors.\n",
    "                                                                    # values: A 1D array containing the eigenvalues of mat_A.\n",
    "                                                                    # left: A 2D array where the columns are the left eigenvectors of mat_A.\n",
    "        \n",
    "print(\"left eigen vectors = \\n\", left, \"\\n\")  \n",
    "print(\"eigen values = \\n\", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90853685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.35211267605633795-0j), (0.21126760563380292-0j), (0.43661971830985913-0j)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the cell above we see that only the first column contains real numbers in both the left eigen vector and eigen values output\n",
    "\n",
    "# We also see that the left eigen vectors are negative and do not sum up to 1 as it should\n",
    "\n",
    "#so? We normalise\n",
    "\n",
    "\n",
    "pi = left[:,0]              #notation selects all rows and only first column (indexed at 0) in \"left\" (from \"values, left = scipy.linalg.eig\" above)\n",
    "pi_normalised = [(x/np.sum(pi).real) for x in pi]     # np.sum(pi).real: This calculates the sum of the elements of pi and takes the real part. Because of floating point calculations, even if the components of pi should be real, there could be a tiny, imaginary component. Taking the real part is a way to address this.\n",
    "                                                      # (x/np.sum(pi).real): Each element x of pi is divided by the sum of all elements in pi, effectively normalizing the vector so that its elements sum to 1.\n",
    "                                                      # [...]: The list comprehension creates a new list pi_normalised containing the normalized elements.\n",
    "pi_normalised\n",
    "\n",
    "\n",
    "#output is accurate and identical to other approaches. Instructor identifies approach as most accurate and preferred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cacec94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.036971830985915506+0j)\n"
     ]
    }
   ],
   "source": [
    "#### Now how abt computing the Prb for a specific sequence?   #####\n",
    "#*** Pizza = P, Hotdog = H, Burger = B\n",
    "\n",
    "## Consider the ff  sequence:\n",
    "\n",
    "# P(P -> H -> H -> B) =?\n",
    "\n",
    "# i.e., => P(X_0  = P, X_1 = H, X_2 = H, X_3 = B)\n",
    "#       => P(X_0) * P(X_1 | X_0) * P(X_2 | X_1) * P(X_3 | X_2)\n",
    "\n",
    "\n",
    "def find_prob(seq, mat_A, pi):\n",
    "    start_state = seq[0]\n",
    "    prob = pi[start_state]\n",
    "    prev_state = start_state\n",
    "    for i  in range(1, len(seq)):\n",
    "        curr_state = seq[i]\n",
    "        prob *= mat_A[prev_state][curr_state]\n",
    "        prev_state = curr_state\n",
    "    return prob\n",
    "\n",
    "print(find_prob([1, 2, 2, 0], mat_A, pi_normalised))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
