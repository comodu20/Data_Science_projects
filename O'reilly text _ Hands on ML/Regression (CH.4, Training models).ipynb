{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b839707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to train a linear regresssion model\n",
    "# How?:\n",
    "##|training a model means setting its parameters so that the model best fits the training set. \n",
    "##|- For this purpose, we first need a measure of how well (or poorly) the model fits the training data. \n",
    "##|- The most common performance measure of a regression model is the Root Mean Square Error (RMSE). \n",
    "##|- Therefore, to train a Linear Regression model, we need to find the value of θ (theta = weights/coefficients) that minimizes the RMSE. \n",
    "##|- In practice, it is simpler to minimize the mean squared error (MSE) than the RMSE, and it leads to the same result \n",
    "#########|- (because the value that minimizes afunction also minimizes its square root).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f9120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[4.58067362],\n",
       "       [2.93622574]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Normal Eqn\n",
    "####|- See Moore-Penrose Pseudo-inverse for Min. Norm. Least squares soln. (pg 13, ch2. Math for ML - OneNote)\n",
    "\n",
    "\n",
    "#Let’s generate some linear-looking data to test this equation:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x= 2 * np.random.rand(100,1)      # \"np.random.rand(100, 1)\" -> generates a 100x1 array of random numbers between 0 (inclusive) and 1 (exclusive) following a uniform distribution \n",
    "                                  # \"2 *\" -> multiplies each element in the array by 2, resulting in values b/w 0 and 2\n",
    "\n",
    "y = 4 + 3 * x + np.random.rand(100,1)      # creating linear rel. b/w y and x + random noise (np.random.rand(100,1) )\n",
    "                                           \n",
    "    \n",
    "# Now let’s compute bar(θ ) (bar(theta) = weights vector -> and soln of the least sq. mthd) using the Normal Equation. \n",
    "# We will use the inv() function from NumPy’s linear algebra module (np.linalg) to compute the inverse of a matrix, and the dot() method for matrix multiplication:\n",
    "\n",
    "x_b = np.c_[np.ones((100, 1)), x]   ## add x0 = 1 to each instance -> # \"np.ones((100, 1))\" creates a 100x1 array filled with ones. \n",
    "                                                                      # This represents the bias term (x0) in linear regression, which is typically set to 1 for all data points\n",
    "                                                                      # \"np.c_[..., ...]\" combines arrays column-wise (c stands for column). \n",
    "                                                                      ####|- Here, it combines the array of ones with the original 'x' features, creating a new 100x2 array where the first column is always 1....\n",
    "                                                                      ########| - ....and the second column is the original feature value.\n",
    "                                                            \n",
    "\n",
    "theta_best = np.linalg.inv(x_b.T.dot(x_b)).dot(x_b.T).dot(y)   # This formula is the same as the normal eqn (i.e. least sq. soln)\n",
    "\n",
    "# The function that we used to generate the data is y = 4 + 3x_1 + Gaussian noise (see y above).\n",
    "\n",
    "#theta_best #***running at this point (take out has sign at the strt of this line) gives coeff. = 4.446; 3.0499\n",
    "\n",
    "# We would have hoped for θ0 = 4 and θ1 = 3 instead of θ0 = 4.446 and θ1 = 3.0499. \n",
    "# Close enough, but the noise made it impossible to recover the exact parameters of the original function.\n",
    "\n",
    "# Now we can make predictions using bar(θ):\n",
    "\n",
    "x_new = np.array([[0],[2]])\n",
    "x_new_b = np.c_[np.ones((2,1)), x_new]  # add x0 = 1 to each instance\n",
    "y_predict = x_new_b.dot(theta_best)             #****Math is basically 2x2 matrix * 2x1 matrix\n",
    "\n",
    "\n",
    "#y_predict\n",
    "\n",
    "# Let’s plot this model’s predictions:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_new, y_predict, \"r-\")\n",
    "plt.plot(x,y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()\n",
    "\n",
    "# Performing Linear Regression using Scikit-Learn is simple:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x, y)\n",
    "#lin_reg.intercept_, lin_reg.coef_\n",
    "# lin_reg.predict(x_new)        ### apply hash as needed above line or below for desired output\n",
    "\n",
    "\n",
    "#The LinearRegression class is based on the scipy.linalg.lstsq() function (the name stands for “least squares”), which you could call directly:\n",
    "\n",
    "theta_best_svd, residuals, rank, s = np.linalg.lstsq(x_b, y, rcond=1e-6)\n",
    "\n",
    "#theta_best_svd\n",
    "\n",
    "\n",
    "#You can use np.linalg.pinv() to compute the pseudoinverse directly:\n",
    "\n",
    "np.linalg.pinv(x_b).dot(y)\n",
    "\n",
    "# The pseudoinverse itself is computed using SVD\n",
    "# The training set is decomposed into the matrix multiplication of three matrices U Σ V⊺\n",
    "# This approach is more efficient than computing the Normal Equation, \n",
    "# plus it handles edge cases nicely: indeed, the Normal Equation may not work if the matrix X⊺X is not invertible (i.e., singular)....,\n",
    "#.... such as if m < n or if some features are redundant, but the pseudoinverse is always defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c91d98c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.80617207],\n",
       "       [1.        , 1.4613345 ],\n",
       "       [1.        , 0.37318492],\n",
       "       [1.        , 1.93313333],\n",
       "       [1.        , 1.03820433],\n",
       "       [1.        , 1.09184806],\n",
       "       [1.        , 0.89693834],\n",
       "       [1.        , 0.41223356],\n",
       "       [1.        , 1.4702385 ],\n",
       "       [1.        , 1.05042497],\n",
       "       [1.        , 1.35834831],\n",
       "       [1.        , 0.40199079],\n",
       "       [1.        , 1.85335654],\n",
       "       [1.        , 1.78111182],\n",
       "       [1.        , 1.27663628],\n",
       "       [1.        , 1.15869093],\n",
       "       [1.        , 0.58040543],\n",
       "       [1.        , 1.56292491],\n",
       "       [1.        , 0.10148231],\n",
       "       [1.        , 0.75261519],\n",
       "       [1.        , 1.41720551],\n",
       "       [1.        , 1.41781873],\n",
       "       [1.        , 0.30883288],\n",
       "       [1.        , 0.621369  ],\n",
       "       [1.        , 1.81867525],\n",
       "       [1.        , 0.74547011],\n",
       "       [1.        , 0.78412666],\n",
       "       [1.        , 1.56060167],\n",
       "       [1.        , 1.05702162],\n",
       "       [1.        , 1.24407457],\n",
       "       [1.        , 0.72340822],\n",
       "       [1.        , 1.47774719],\n",
       "       [1.        , 1.10384557],\n",
       "       [1.        , 0.24075932],\n",
       "       [1.        , 1.93238474],\n",
       "       [1.        , 1.93164645],\n",
       "       [1.        , 0.7667457 ],\n",
       "       [1.        , 0.2584679 ],\n",
       "       [1.        , 1.06766198],\n",
       "       [1.        , 0.47227677],\n",
       "       [1.        , 0.10435444],\n",
       "       [1.        , 1.3028373 ],\n",
       "       [1.        , 1.49515824],\n",
       "       [1.        , 0.72128306],\n",
       "       [1.        , 0.06121724],\n",
       "       [1.        , 1.19110173],\n",
       "       [1.        , 1.91970069],\n",
       "       [1.        , 1.84080383],\n",
       "       [1.        , 0.02464825],\n",
       "       [1.        , 1.8611882 ],\n",
       "       [1.        , 0.1282812 ],\n",
       "       [1.        , 0.33838183],\n",
       "       [1.        , 1.16014521],\n",
       "       [1.        , 0.22922659],\n",
       "       [1.        , 1.97687715],\n",
       "       [1.        , 0.05299488],\n",
       "       [1.        , 1.02361063],\n",
       "       [1.        , 1.20519017],\n",
       "       [1.        , 0.29466141],\n",
       "       [1.        , 1.42476869],\n",
       "       [1.        , 0.4747407 ],\n",
       "       [1.        , 0.20092452],\n",
       "       [1.        , 0.79812235],\n",
       "       [1.        , 0.85229636],\n",
       "       [1.        , 1.04551627],\n",
       "       [1.        , 1.4202639 ],\n",
       "       [1.        , 0.64751321],\n",
       "       [1.        , 0.90239399],\n",
       "       [1.        , 1.44887746],\n",
       "       [1.        , 1.92645377],\n",
       "       [1.        , 1.2341348 ],\n",
       "       [1.        , 0.29167928],\n",
       "       [1.        , 1.85514727],\n",
       "       [1.        , 0.96885044],\n",
       "       [1.        , 0.03620753],\n",
       "       [1.        , 0.04390267],\n",
       "       [1.        , 1.8148143 ],\n",
       "       [1.        , 0.29431294],\n",
       "       [1.        , 1.14873143],\n",
       "       [1.        , 1.5599469 ],\n",
       "       [1.        , 1.50683253],\n",
       "       [1.        , 1.11053644],\n",
       "       [1.        , 0.66734248],\n",
       "       [1.        , 1.39450631],\n",
       "       [1.        , 0.17109586],\n",
       "       [1.        , 1.98710326],\n",
       "       [1.        , 0.91777811],\n",
       "       [1.        , 1.30987215],\n",
       "       [1.        , 1.02220567],\n",
       "       [1.        , 1.98987398],\n",
       "       [1.        , 1.08568686],\n",
       "       [1.        , 0.14632666],\n",
       "       [1.        , 0.94541392],\n",
       "       [1.        , 1.10807392],\n",
       "       [1.        , 1.28175222],\n",
       "       [1.        , 1.04225297],\n",
       "       [1.        , 1.19596498],\n",
       "       [1.        , 0.00401359],\n",
       "       [1.        , 1.34637984],\n",
       "       [1.        , 1.39508858]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x= 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * x + np.random.rand(100,1)\n",
    "\n",
    "\n",
    "x_b = np.c_[np.ones((100, 1)), x] \n",
    "\n",
    "#x\n",
    "x_b       #You can now see what's meant above by \"Adding x0 = 1 to each instance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659413c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morgpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
